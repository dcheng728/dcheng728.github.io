<!DOCTYPE html>

<html>
    <head>
        <title>Chang "Davidson" Cheng</title>
        <meta charset=utf-8>
        <link rel="stylesheet" type="text/css" href="style.css">
        <script src="loadSidebar.js"></script>
    </head>

    <style>
        table, th, td {
          border:1px solid black;
          border-collapse: collapse;
        }
    </style>

    <body id="homeBody">
        <script src="stickgame.js"></script>
    
        <div id="homeTextDiv" style="margin-left:0%; margin-top:0%; line-height:120%">

            <p class="publicationHeading">AI/ML Projects</p>
            <hr>


            <div style="width:100%; display:inline-block; ">


                <div>
                    <h2 id="Point Cloud Representation Learning">Point Cloud Representation Learning (2023)</h2>
                        <p>
                            Point clouds arise in settings such as LiDAR for self-driving cars, yet raw coordinates carry little meaning: they shift under translation and are easily distorted by noise and sensor biases. 
                            Our goal was to develop a representation that reflects the underlying geometry rather than the coordinates themselves.
                        </p>
                        <center>
                            <img src="media/point cloud example.png" width="50%"  />
                            <p>Example point clouds of 3D objects.</p>
                        </center>
                        <p>
                            We trained a graph neural network to map each point cloud to a feature vector, while an adversarial network applied perturbations to the input aimed at mimicking various symmetries and noise that the main network should be insensitive to. 
                            The adversarial network sought to maximize deviations in the learned features, while the main network attempted to remain invariant. 
                            Training the two networks jointly led to stable and promising geometric representations.
                        </p>
                        <center>
                            <img src="media/point cloud perturbation.png" width="50%"  />
                            <p>Example of how the Adversarial Neural Network applies perturbations.</p>
                        </center>
                        <p>
                            <a href="https://github.com/dcheng728/ML-HKS">Github Repo</a>
                        </p>

                    <hr>
                    <h2 id="Machine Learning Auction Design">Machine Learning in Auction Design (2022)</h2>

                    <p>
                        In summer 2022, I participated in an REU program at the University of Maryland.
                        We were interested in building sealed-bid online auctions that people could actually trust, even when the auctioneer might have reasons to bend the rules. 
                        We realized that you canâ€™t get truthfulness, high revenue, and credibility all at once in a single-round auction, so we looked at how repeated auctions could give bidders a way to check whether the auctioneer was behaving honestly.
                        We used machine learning to learn good auction rules. 
                        To keep the auctioneer honest, we added an audit step.
                        Putting everything together, we ended up with a system that performs well and stays trustworthy without adding much overhead.
                        <center>
                            <img src="media/group picture.png" width="50%"  />
                            <p>REU Group Picture. </p>
                        </center>
                        <center>
                            <img src="media/reu picture.png" width="50%"  />
                            <p>Photo of those of us with Math/CS shirts. </p>
                        </center>
                    </p>
                    
                    <!-- <p>
                            My experience: <a href="https://storymaps.arcgis.com/stories/968d66af1b3645a987ac20a4095f8829">Storymaps</a>
                    </p> -->

                    <hr>
                    <h2 id="lol_section">Machine Learning in Video Game (2020)</h2>
                        <p>
                            I once played a video game called League of Legnds.
                            The game has a minimap, which contains key information, e.g. where the players' allies and enemies are located.
                            But it is very easy to overlook the minimap. 
                            I wanted to create an AI that would summarize the key information on the minimap.

                        </p>

                        <center>
                            <img src="media/lol example.jpg" width="50%"  />
                            <p>In-game interface of League of Legends.</p>
                        </center>

                        <p>
                            The program extracted champion icons directly from minimap frames using image-processing techniques, 
                            then a neural network is applied to classify each icon. 
                            
                            <center>
                                <img src="media/classification pipeline.png" width="50%"  />
                                <p>The pipeline for avatar recognition.</p>
                            </center>

                            <center>
                                <img src="media/leagueX demo.gif" width="50%"  />
                                <p>Demo of the pipeline running live.</p>
                            </center>
                        </p>
                        <!-- <p>
                            To learn the necessary knowledge for ML and computer vision, I became close with my high school librarian Mrs. Villages.
                        </p> -->
                        <p>
                            I received an award for this project at graduation, and my high school began offering computer science classes in the following year.
                        </p>
                        <p>
                            <a href="https://github.com/dcheng728/League-X">Github Repo</a>;
                            Blog Posts (in Chinese):
                            <a href="https://blog.csdn.net/weixin_42488182/article/details/95088716?spm=1001.2014.3001.5501">part I</a>,
                            <a href="https://blog.csdn.net/weixin_42488182/article/details/105161123?spm=1001.2014.3001.5501">part II</a>.
                        </p>
            
                        <hr>
            
                        <h2 id="rubik_section">Rubik's Cube Scanner + Solver (2018)</h2>
                        
                        
                        <p>
                            I used OpenCV, various computer vision algorithms and filters to create a program that could recognize the faces of a Rubik's Cube.
                            

                            <center>
                                <img src="media/rubik demo.gif" width="70%"  />
                                <p>Demo of my rubik's cube scanner + solver.</p>
                            </center>

                            My program is actively scanning for rubik's cubes in the webcam image, and when it recognizes one, it will read the colors and automatically enter them into the solver.
                            The solver then finds the solution and displays an animation of how to solve the cube.
                        </p>
                        <p>
                            <a href="https://github.com/dcheng728/Rubik-s-Cube-Scanner-Solver">Github Repo</a>, 
                            <a href="https://blog.csdn.net/weixin_42488182/article/details/103451877?spm=1001.2014.3001.5501">Blog Post (in Chinese)</a>
                        </p>


                        <!-- <hr>
                        <h2 id="rps_section">Rock Paper Scissors Machine (2020)</h2>
                        <p>
                            Now days, computers are just beating humans at everythings, chess, GO, even DOTA2. 
                            How about Rock Paper Scissors? 
                            The optimal strategy to play Rock Paper Scissors is indeed play randomly, can humans' faith be restored in this classic game?
                            The answer is NO. In the spring of 2020, I gained access to a <a href="https://www.ultraleap.com/product/leap-motion-controller/">Leap Motion Controller</a>, tool
                            that can be used to track hand motions. 
                            I gathered enough data to train a neural network that would recognize the three gestures of Rock Paper Scissors, and used it to play against others. 

                            <center>
                                <img src="media/rps demo.gif" width="700"  />
                                <p>Demo of the computer rock paper scissors player.</p>
                            </center>

                            The program is not actually "predicting" what the human will play next, it is classifying the human's hand motion into one of the three categories, then reacting very quickly.
                            So technically, the computer is cheating, but does that mean faith in humanity can be restored?
                        </p> -->

                </div>

            </div>


            

            
           






        </div>

        



    </body>
</html> 