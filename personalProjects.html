<!DOCTYPE html>

<html>
    <head>
        <title>Chang "Davidson" Cheng</title>
        <meta charset=utf-8>
        <link rel="stylesheet" type="text/css" href="style.css">
    </head>

    <style>
        table, th, td {
          border:1px solid black;
          border-collapse: collapse;
        }
    </style>

    <div class="sidenav">
        <a href="index.html">Homepage</a>
        <a href="publications.html">Publications</a>
        <a href="researchHighlights.html">Research Highlights</a>
        <a href="personalProjects.html">Personal Projects</a>
    </div>

    <body id="homeBody">
        
    
        <div id="homeTextDiv" style="margin-left:-7%; margin-top:-6%; line-height:120%">

            <p class="publicationHeading">Personal Projects</p>
            <hr>


            <div style="width:100%; display:inline-block; ">

                <div style = 'float:left; width: 20%;'>
                    <div style = 'position: fixed;line-height:150%'>
                        <div id="toc_container">
                            <p class="toc_title">Contents</p>
                            <ul class="toc_list">
                              <li><a href="#grasp_planning_algorithms_section">Deep Learning in Video Game</a>
                              <li><a href="#Arc_Channel_pelvis_fixation_path_algorithms_section">Rubik's Cube Scanner + Solver</a></li>
                              <li><a href="#soft_robotics_section">Rock Paper Scissors Machine</a></li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div style = 'float:right; width:70%'>
                    <h2 id="grasp_planning_algorithms_section">Deep Learning in Video Game</h2>
                        <p>
                            This project started in January 2019, when I was very enthuisastic about the video game "League of Legends".
                            In case you don't know what this game is about, League of Legends is a 5v5 multiplayer online game.
                            The "minimap" is on the bottom of a player's screen, it provides a lot of macro-information about what the player's teammates and opponents are doing.
                            Therefore, it is really important to look at the minimap once in a while, but a lot of players often forget.
                            So I thought, can I create an AI that constantly keeps track of the minimap, and summarize the information for me?

                        </p>

                        <center>
                            <img src="media/lol example.jpg" width="800"  />
                            <p>In-game interface of League of Legends.</p>
                        </center>

                        <p>
                            I wanted to extract information from the game without hacking the server, which will get me banned.
                            My idea was to use image recognition, I want an AI to recognize the avatars on the screen and keep track of where my enemies are.
                            My pipeline begins with a image processing algorithm that extracts the avatars from the minimap image. 
                            Then individually, the avatar images are passed to a image classification network which will label the avatars, and we know what enemy is where on the map.   
                            
                            <center>
                                <img src="media/classification pipeline.png" width="700"  />
                                <p>The pipeline for avatar recognition.</p>
                            </center>

                            <center>
                                <img src="media/leagueX demo.gif" width="700"  />
                                <p>Demo of the pipeline running live.</p>
                            </center>

                            I detailed my approach in two posts on CSDN (in Chinese): 
                            <a href="https://blog.csdn.net/weixin_42488182/article/details/95088716?spm=1001.2014.3001.5501">part I</a>,
                            <a href="https://blog.csdn.net/weixin_42488182/article/details/105161123?spm=1001.2014.3001.5501">part II</a>.

                        </p>
            
                        <hr>
            
                        <h2 id="Arc_Channel_pelvis_fixation_path_algorithms_section">Rubik's Cube Scanner + Solver</h2>
                        
                        
                        <p>
                            Rubik's cubes is one of my hobbies. In winter 2018, I wanted to make a program that can solve rubik's cube for those who do not know how.
                            Fun fact, the maximum minimunm number of steps needed to solve any rubik's cube configuration is called <a href="https://www.cube20.org/">"God's Number"</a>.
                            It was only recently proven that God's number is 20, and it has only been proven by solving every 46 quintillion configurations of the rubik's cube using a computer.
                            At the time, there were already plenty of programs that can solve rubik's cubes, but the user have to enter the color of every face of the cube, which is tiring.
                            So I thought, wouldn't it be nice if my program can scan the facets of the rubik's cube using the webcam, and then solve it for the user?
                            

                            <center>
                                <img src="media/rubik demo.gif" width="700"  />
                                <p>Demo of my rubik's cube scanner + solver.</p>
                            </center>

                            My program is actively scanning for rubik's cubes in the webcam image, and when it recognizes one, it will read the colors and automatically enter them into the solver.
                            The solver then finds the solution and displays an animation of how to solve the cube.

                            My source codes are accessible at <a href="https://github.com/dcheng728/Rubik-s-Cube-Scanner-Solver">github</a>, and I wrote a post about this program (in Chinese) at <a href="https://blog.csdn.net/weixin_42488182/article/details/103451877?spm=1001.2014.3001.5501">CSDN</a>.

                        </p>


                        <hr>

                        <h2 id="soft_robotics_section">Rock Paper Scissors Machine</h2>
                        <p>
                            When most people think about robots, they picture a rigid humanoid built with metals.
                            Traditionally, robotics have been built with rigid materials for durability and precision. 
                            However, there are tasks that we wish a robotic system can be "soft".
                            For example, when a robot needs to interact with humans or handle delicate objects. 
                            At Beihang University between June 2018 and August 2021, I participated in several projects in design and innervation of soft robotics.

                            <div style="width:100%; display:inline-block; ">

                                <div style = 'float:left; width: 5%;'>

                                </div>
                
    
                                <div style = 'float:right; width:95%'>
                                    <h3 id="design_of_an_anthropomorphic_finger_section">Anthropomorphic finger</h3>

                                    <p>With another PhD student, we designed a soft robotic finger with three degrees of freedom that can mimick the full range of motion of that of a finger.
                                        The finger is 3D printed using nylon with notches carved into it. The notches are arranged in a specific way that it only allows joint-like rotation rather than shrinkage or elongation in the axial direction. 
                                    </p>
                                        <div style="width:100%; display:inline-block; ">

                                            <div style = 'float:left; width: 70%;'>

                                                <center>
                                                    <img src="media/finger functions.JPG" height="220"  />
                                                    <p>Our finger performing human motions.</p>
                                                </center>
                                                
                                            </div>
                            
                
                                            <div style = 'float:right; width:30%'>
                                                <center>
                                                    <img src="media/finger inhand manipulation.JPG" width= "180"  />
                                                    <p>Our finger performing in-hand manipulations.</p>
                                                </center>
                                            </div>
                                        </div>

                                        <p>This soft finger proposal has been applied onto both robotic grippers and prosthetic hands.
                                            The benefit of using soft fingers on hands is that the soft material is compliant in nature, so it can adapt to the surface geometry of the object it
                                            is trying to grasp.     
                                        </p>
                                        
                                </div>
                            </div>

                            <div style="width:100%; display:inline-block; ">

                                <div style = 'float:left; width: 5%;'>

                                </div>
                
    
                                <div style = 'float:right; width:95%'>
                                    <h3 id="innervation_of_soft_robotics_section">Innervation of Soft Robotics</h3>

                                    <p>Soft robotics are superior to rigid robotics in compliance and adaptability, but this comes with the price of much harder kinematic modeling and sensorization.
                                        Innervation means "to give something the ability to sense". For traditional rigid robots, the robot's movement in response to actuation is much more predictable: most can be modeled using classical physics or trignometric equations.
                                        However, for soft robotics, a lot of times we don't know how it will behave, and this makes innervating soft robotics a persistent challenge in the soft robotics community.
                                        We came up with a biomimetic design to allow soft manipulators to sense. 
                                        The proprioception framework in human body is how we feel where our body parts are at and how heavy things are, when someone is trying to stand on one foot with their eyes closed, they are using their proprioception. 
                                        We applied this mechanism to soft robotics, and by using machine learning algorithms, we were able to distinguish 8 different textures with a soft robotic finger.

                                        <div style="width:100%; display:inline-block; ">

                                            <div style = 'float:left; width: 50%;'>

                                                <center>
                                                    <img src="media/proprioception framework.png" width= "400"  />
                                                    <p>The human proprioception framework (top) and our sensing mechanism (bottom).</p>
                                                </center>
                                                
                                            </div>
                            
                
                                            <div style = 'float:right; width:50%'>
                                                <center>
                                                    <br>
                                                    <br>
                                                    <br>
                                                    <img src="media/sensing experiment.JPG" width= "450"  />
                                                    <p>Our robotic finger is capable of palpating different objects to identify which is which. 
                                                        It achieves 99% 6-fold cross validation accuracy when identifying 8 different textures. </p>
                                                </center>
                                            </div>
                                        </div>

                                    </p>
                                        
                                </div>
                            </div>


                        </p>

                        <hr>

                        <h2 id="identifying_price_discrimination_in_apple_section">Price Discrimination Identification in Apple Inc. <img class="institutionLogo" src="media/apple logo.png"/></h2>
                        <p>
                            Naturally, consumers with different sensitivities towards prices exist in a market. 
                            Firms may choose to take advantage of such varying price sensitivity to maximize profit. 
                            This practice is called price discrimination or personalized pricing. 
                            Apple Inc. is considered by many to have changed the personalized computer and phone industry, it is also once the worldâ€™s largest company with market capitalization in the trillions. 
                            The iPhone is a popular product from Apple sold across the globe. 
                            In fact, the prices of iPhones vary in an interesting fashion across different markets. 
                            For example, the iPhone 13 with 128gb of storage is sold at $799 in the U.S. and roughly $1441 in Brazil, a much less developed economy. 
                            Selling iPhones in Brazil definitely requires additional costs that may otherwise be avoided in the U.S. But when those additional costs are accounted for, are iPhones still price higher in countries such as Brazil than in the U.S?
                            
                            <br>

                            I was interested in finding out whether geo-economical factors affect the price of iPhones in different countries when differentiated costs are accounted for.
                            In my work, I adopted Stigler's definition for price discrimination, gathered price of iPhones and socioeconomical data from 53 countries where Apple Inc. sell their products, and performed econometric analysis.
                            I found strong statistical evidence of Apple utilizing its market power to increase profit. Specifically, iPhones are <br> 
                            <div style="width:100%; display:inline-block; ">

                                <div style = 'float:left; width: 5%;'>
                                </div>
                
    
                                <div style = 'float:right; width:95%'>
                                    (1) significantly more expensive (p < 0.01) in markets where Apple has a high market share <br>
                                    (2) significantly more expensive (p < 0.01) in economies with high gini index (high gini index -> high income inequality</0.01>) <br>
                                    (3) significantly more expensive (p < 0.01) in upper-middle-income economies (another word for developing countries) 
                                    
                                </div>
                                
                            </div>

                        </p>
                
                </div>

            </div>


            

            
           






        </div>

        



    </body>
</html> 